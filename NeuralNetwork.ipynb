{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Forward propagation **\n",
    "$$O^{[1]} = W1^{[1]}State + B^{[1]}$$\n",
    "$$G^{[1]} = {f_\\text{ReLU}}(O^{[1]})$$\n",
    "$$O^{[2]} = W^{[2]}G^{[1]} + B^{[2]}$$\n",
    "$$G^{[2]} = {f_\\text{ReLU}}(O^{[2]})$$\n",
    "$$O^{[3]} = W^{[3]} G^{[2]} + B^{[3]}$$\n",
    "$$Loss = (Y-O^{[3]})^{2}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape**\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{O3}}}: A * 1$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{W3}}}: A * 128$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{B3}}}: A * 1$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{G2}}}: 128 * 1$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{W2}}}: 128 * 128$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation**\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{O3}}} = 2(O^{[3]}-Y)$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{W3}}} = \\frac{d_\\text{L}}{{d_\\text{O3}}} \\frac{d_\\text{O3}}{{d_\\text{W3}}} = \\frac{d_\\text{L}}{{d_\\text{O3}}} G^{[2]T} {(*)}$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{B3}}} = \\frac{d_\\text{L}}{{d_\\text{O3}}} \\frac{d_\\text{O3}}{{d_\\text{B3}}} = \\frac{d_\\text{L}}{{d_\\text{O3}}} 1^{T} {(*)}$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{G2}}} = \\frac{d_\\text{L}}{{d_\\text{O3}}} \\frac{d_\\text{O3}}{{d_\\text{G2}}} = W^{[3]T} \\frac{d_\\text{L}}{{d_\\text{O3}}}$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{W2}}} = \\frac{d_\\text{L}}{{d_\\text{G2}}} \\frac{d_\\text{G2}}{{d_\\text{O2}}}\\frac{d_\\text{O2}}{{d_\\text{W2}}} = \\frac{d_\\text{L}}{{d_\\text{G2}}} * {(O^{[2]}>0)} * {G^{[1]T}} {(*)}$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{B2}}} = \\frac{d_\\text{L}}{{d_\\text{G2}}} \\frac{d_\\text{G2}}{{d_\\text{O2}}}\\frac{d_\\text{O2}}{{d_\\text{B2}}} = \\frac{d_\\text{L}}{{d_\\text{G2}}} * {(O^{[2]}>0)} * {1^{[1]T}} {(*)}$$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{G1}}} = \\frac{d_\\text{L}}{{d_\\text{G2}}} \\frac{d_\\text{G2}}{{d_\\text{O2}}}\\frac{d_\\text{O2}}{{d_\\text{G1}}} ={W^{[2]T}}*\\frac{d_\\text{L}}{{d_\\text{G2}}}*{(O^{[2]}>0)} $$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{W1}}} = \\frac{d_\\text{L}}{{d_\\text{G1}}} \\frac{d_\\text{G1}}{{d_\\text{O1}}} \\frac{d_\\text{O1}}{{d_\\text{W1}}} = \\frac{d_\\text{L}}{{d_\\text{G1}}} * {(O^{[1]}>0)} * State^{T} {(*)} $$\n",
    "$$\\frac{d_\\text{L}}{{d_\\text{B1}}} = \\frac{d_\\text{L}}{{d_\\text{G1}}} \\frac{d_\\text{G1}}{{d_\\text{O1}}} \\frac{d_\\text{O1}}{{d_\\text{B1}}} = \\frac{d_\\text{L}}{{d_\\text{G1}}} * {(O^{[1]}>0)} * 1^{T} {(*)} $$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update**\n",
    "$${W^{[3]} = W^{[3]} - \\frac{d_\\text{L}}{{d_\\text{W3}}}}$$\n",
    "$${B^{[3]} = W^{[3]} - \\frac{d_\\text{L}}{{d_\\text{B3}}}}$$\n",
    "$${W^{[2]} = W^{[2]} - \\frac{d_\\text{L}}{{d_\\text{W2}}}}$$\n",
    "$${B^{[2]} = W^{[2]} - \\frac{d_\\text{L}}{{d_\\text{B2}}}}$$\n",
    "$${W^{[1]} = W^{[1]} - \\frac{d_\\text{L}}{{d_\\text{W1}}}}$$\n",
    "$${B^{[1]} = W^{[1]} - \\frac{d_\\text{L}}{{d_\\text{B1}}}}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def forward(W1,b1,W2,b2,W3,b3,X):\n",
    "    O1 = W1 @ X.T + b1\n",
    "    G1 = np.maximum(0,O1)\n",
    "    O2 = W2 @ G1 + b2\n",
    "    G2 = np.maximum(0,O2)\n",
    "    O3 = W3 @ G2 + b3\n",
    "    return O1,O2,O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def mean_numba(X):\n",
    "    R = []\n",
    "    for i in np.arange(X.shape[0]):\n",
    "        R.append(X[i,:].mean())\n",
    "    return np.array(R).reshape(-1,1) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def backward(W1,b1,W2,b2,W3,b3,S,Y,O1,O2,O3,lr):\n",
    "    # print(O3.shape,Y.shape)\n",
    "    dO3 = (O3-Y.T)\n",
    "    dG2 =  W3.T.dot(dO3)\n",
    "    dG1 = W2.T.dot(dG2 * (O2 >= 0))\n",
    "    dW1 =  (dG1 * (O1 >= 0)).dot(S)\n",
    "    dB1 = mean_numba(dG1 * (O1 >= 0))#np.mean(dG1 * (O1 > 0)) #\n",
    "    dW2 = (dG2 * (O2 >= 0)).dot(np.maximum(0,O1).T)\n",
    "    dB2 = mean_numba(dG2 * (O2 >= 0)) #dG2 * (O2 > 0) * np.ones_like(b2) / b2[0]#np.mean(dG2 * (O2 > 0))#\n",
    "    dW3 = dO3.dot(np.maximum(0,O2).T)\n",
    "    dB3 = mean_numba(dO3) #dO3 * np.ones_like(b3) / b3[0] #np.mean(dO3)#\n",
    "    # print(dB1,dW1,dW2,dB2,dW3,dB3)\n",
    "    # print()\n",
    "    W1 = W1 - dW1*lr\n",
    "    b1 = b1 - dB1*lr\n",
    "    W2 = W2 - dW2*lr\n",
    "    b2 = b2 - dB2*lr\n",
    "    W3 = W3 - dW3*lr\n",
    "    b3 = b3 - dB3*lr\n",
    "    return W1,b1,W2,b2,W3,b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def batchLoader(S,Y,batch_size=16):\n",
    "    n_samples = S.shape[0]\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    S,Y = S[idx],Y[idx]\n",
    "    for i in np.arange(0, n_samples, batch_size):\n",
    "        begin, end = i, min(i + batch_size, n_samples)\n",
    "        yield S[begin:end] , Y[begin:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def updateParams(W1,b1,W2,b2,W3,b3,S,Y,batch_size=16,lr=1e-4):\n",
    "    n_samples = S.shape[0]\n",
    "    idx = np.arange(n_samples)\n",
    "    np.random.shuffle(idx)\n",
    "    S,Y = S[idx],Y[idx]\n",
    "    for i in np.arange(0, n_samples, batch_size):\n",
    "        begin, end = i, min(i + batch_size, n_samples)\n",
    "        s,y =  S[begin:end] , Y[begin:end]\n",
    "        O1,O2,O3 = forward(W1,b1,W2,b2,W3,b3,s)\n",
    "        W1,b1,W2,b2,W3,b3 = backward(W1,b1,W2,b2,W3,b3,s,y,O1,O2,O3,lr)\n",
    "    return W1,b1,W2,b2,W3,b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def MSELoss(y_true,y_pred):\n",
    "    return np.mean(np.square(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def fitModel(X,y,n_iter=10,batch_size=16,lr=1e-4):\n",
    "    W1 = np.random.uniform(low=-1/np.sqrt(X.shape[1]),high=1/np.sqrt(X.shape[1]),size=(128 ,X.shape[1]))\n",
    "    b1 = np.zeros((128,1)) * 1.0\n",
    "    W2 = np.random.uniform(low=-1/np.sqrt(128),high=1/np.sqrt(128),size=(256,128))\n",
    "    b2 = np.zeros((256,1)) * 1.0\n",
    "    W3 = np.random.uniform(low=-1/np.sqrt(256),high=1/np.sqrt(256),size=(1,256))\n",
    "    b3 = np.zeros((1,1)) * 1.0\n",
    "    for _ in range(n_iter):\n",
    "        W1,b1,W2,b2,W3,b3 = updateParams(W1,b1,W2,b2,W3,b3,X,y,batch_size=batch_size,lr=lr)\n",
    "        if _ % 50 == 0:\n",
    "            print('Epoch ',_, 'Loss: ',MSELoss(y.reshape(1,-1),forward(W1,b1,W2,b2,W3,b3,X)[-1]))\n",
    "    return W1,b1,W2,b2,W3,b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(5000,100)\n",
    "y = np.random.rand(5000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Loss:  0.08635114666072984\n",
      "Epoch  50 Loss:  0.08082980509198207\n",
      "Epoch  100 Loss:  0.0776415378651361\n",
      "Epoch  150 Loss:  0.06797879487076072\n",
      "Epoch  200 Loss:  0.06220985639052793\n",
      "Epoch  250 Loss:  0.03493310705522822\n",
      "Epoch  300 Loss:  0.04079295246170528\n",
      "Epoch  350 Loss:  0.025483490768251054\n",
      "Epoch  400 Loss:  0.02108971258172736\n",
      "Epoch  450 Loss:  0.012204984298374372\n",
      "Epoch  500 Loss:  0.0078330861230184\n",
      "Epoch  550 Loss:  0.0066967331127153785\n",
      "Epoch  600 Loss:  0.004854762148859092\n",
      "Epoch  650 Loss:  0.004852825357050197\n",
      "Epoch  700 Loss:  0.0032607413141964373\n",
      "Epoch  750 Loss:  0.0017909979139159283\n",
      "Epoch  800 Loss:  0.0026756497938496496\n",
      "Epoch  850 Loss:  0.0009765741167316424\n",
      "Epoch  900 Loss:  0.0012509181056471897\n",
      "Epoch  950 Loss:  0.0008276321012981903\n"
     ]
    }
   ],
   "source": [
    "W1,b1,W2,b2,W3,b3 = fitModel(X,y,n_iter=1000,batch_size=500,lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
